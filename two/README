Please answer the following questions to explain your implementation (Directly write your answer below the questions).


1) In your implementation, please describe your strategy/design to count the special words using multiple threads.

I have followed a design approach similar to youtube video about creating and running multiple threads. The idea follows that after the threads are launched, each thread must have a set of file range or indexes to count the special words and keep count updated at all times. For file handling, I have used a struct called as thread_struct which represents each thread's basic structure (contains first and last index holders of int type). This allows me to do the special count process in a multithreaded way where each thread has its own structure. Next, we split the data files into indexes which was challenging since there were 31 files to distribute among num_threads. The files are split based on an assumption of 3 threads such that indexes would become (0-9, 10-19, 20-30) representing ten files for each thread. Next, we implement the thread function to handle all the process and use of mutexes to secure critical sections of the data. For the thread function, I have used my program #0 implementation to count the special words.In addition, a global array (long *freq) to change values and fileList[] was made global to access the files in the thread function for opening it. The placement of mutex was crucial and challenging since my implementation of special word was using mutliple variables used for updating the inner values. Rather than having mutliple mutexes to block every smaller critical region in my code (buff[] and token), I have used a single mutex to handle a larger critical section that starts from opening each file to all the processing ending towards closing each file. This way, the freq[] array is updated once the process of each thread is fineshed and updated in the end to specialfreq[] array to keep the count updated. Lastly, the results are written into "result.txt" file.        


2) In your implementation, please describe how you keep the specialfreq[ ] always having the up-to-date count.

I have used a global array (long *freq) to keep the special word count upto date. After each thread is done processing using the mutex technique, the data in global array is upto date and must update the special freq[] in realtime. Before the pthread_join() function calls for the end of the thread process, the glbbal array must update and to do so we set both arrays equal to each other allowing specialfreq[] to stay upto date for the count.

3) Please measure the total time cost of special word count uisng your program. Please repeat at least three times and write down your time below.

Three total costs are as follows:

real    0m0.864s
user    0m0.844s
sys     0m0.020s

real    0m0.866s
user    0m0.855s
sys     0m0.011s

real    0m0.859s
user    0m0.838s
sys     0m0.020s


4) Can you think of any other improvement in your implementation to speedup the special word count? If no, please briefly justify why you think your design is the best.
 
I cannot think of any other improvements for this program. The simple idea is to utilize least amount of mutexes
to secure critical section and prevent concurrently running threads to access that region. In my design, instead of using multiple mutexes to secure many smaller size critical sections (token, buffer, freq array), I used a single mutex to secure a large critical section (file opening->processing->closing file) than securing smaller sections. This idea has allowed me to speedup my program and output correct results.